{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import PatchTSTConfig, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import PatchTSTForPrediction as PatchTSTForPredictionOG\n",
    "from TimeSeriesJEPA.models import PatchTSTModelJEPA, PatchTSTForPrediction\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
    "from tsfm_public.toolkit.util import select_by_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading target dataset: ETTh2\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "dataset = \"ETTh2\"\n",
    "num_workers = 4  # Reduce this if you have low number of CPU cores\n",
    "batch_size = 32  # Reduce if not enough GPU memory available\n",
    "context_length = 512\n",
    "forecast_horizon = 96\n",
    "patch_length = 8\n",
    "\n",
    "print(f\"Loading target dataset: {dataset}\")\n",
    "dataset_path = r\"D:\\Coursework\\MTS\\dataset\\ETT-small\\ETTh2.csv\"\n",
    "timestamp_column = \"date\"\n",
    "id_columns = []\n",
    "forecast_columns = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "train_start_index = None  # None indicates beginning of dataset\n",
    "train_end_index = 12 * 30 * 24\n",
    "\n",
    "# we shift the start of the validation/test period back by context length so that\n",
    "# the first validation/test timestamp is immediately following the training data\n",
    "valid_start_index = 12 * 30 * 24 - context_length\n",
    "valid_end_index = 12 * 30 * 24 + 4 * 30 * 24\n",
    "\n",
    "test_start_index = 12 * 30 * 24 + 4 * 30 * 24 - context_length\n",
    "test_end_index = 12 * 30 * 24 + 8 * 30 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesPreprocessor {\n",
       "  \"categorical_encoder\": null,\n",
       "  \"conditional_columns\": [],\n",
       "  \"context_length\": 64,\n",
       "  \"control_columns\": [],\n",
       "  \"encode_categorical\": true,\n",
       "  \"feature_extractor_type\": \"TimeSeriesPreprocessor\",\n",
       "  \"freq\": \"0 days 01:00:00\",\n",
       "  \"frequency_mapping\": {\n",
       "    \"10_minutes\": 3,\n",
       "    \"15_minutes\": 4,\n",
       "    \"half_hourly\": 1,\n",
       "    \"hourly\": 2,\n",
       "    \"oov\": 0\n",
       "  },\n",
       "  \"id_columns\": [],\n",
       "  \"observable_columns\": [],\n",
       "  \"prediction_length\": null,\n",
       "  \"processor_class\": \"TimeSeriesPreprocessor\",\n",
       "  \"scaler_dict\": {},\n",
       "  \"scaler_type\": \"standard\",\n",
       "  \"scaling\": true,\n",
       "  \"scaling_id_columns\": [],\n",
       "  \"static_categorical_columns\": [],\n",
       "  \"target_columns\": [\n",
       "    \"HUFL\",\n",
       "    \"HULL\",\n",
       "    \"MUFL\",\n",
       "    \"MULL\",\n",
       "    \"LUFL\",\n",
       "    \"LULL\",\n",
       "    \"OT\"\n",
       "  ],\n",
       "  \"target_scaler_dict\": {\n",
       "    \"0\": {\n",
       "      \"copy\": true,\n",
       "      \"feature_names_in_\": [\n",
       "        \"HUFL\",\n",
       "        \"HULL\",\n",
       "        \"MUFL\",\n",
       "        \"MULL\",\n",
       "        \"LUFL\",\n",
       "        \"LULL\",\n",
       "        \"OT\"\n",
       "      ],\n",
       "      \"mean_\": [\n",
       "        41.53683496078959,\n",
       "        12.273452896210882,\n",
       "        46.60977329964991,\n",
       "        10.526153112865156,\n",
       "        1.1869920139097505,\n",
       "        -2.373217913729173,\n",
       "        26.872023494265697\n",
       "      ],\n",
       "      \"n_features_in_\": 7,\n",
       "      \"n_samples_seen_\": 8640,\n",
       "      \"scale_\": [\n",
       "        10.448841072588488,\n",
       "        4.587112566531959,\n",
       "        16.858190332598408,\n",
       "        3.018605566682919,\n",
       "        4.641011217319063,\n",
       "        8.460910779279644,\n",
       "        11.584718923414682\n",
       "      ],\n",
       "      \"var_\": [\n",
       "        109.17827976021215,\n",
       "        21.04160169803542,\n",
       "        284.19858129011436,\n",
       "        9.111979567209104,\n",
       "        21.538985119281367,\n",
       "        71.58701121493046,\n",
       "        134.20571253452223\n",
       "      ],\n",
       "      \"with_mean\": true,\n",
       "      \"with_std\": true\n",
       "    }\n",
       "  },\n",
       "  \"time_series_task\": \"forecasting\",\n",
       "  \"timestamp_column\": \"date\"\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    dataset_path,\n",
    "    parse_dates=[timestamp_column],\n",
    ")\n",
    "\n",
    "train_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=train_start_index,\n",
    "    end_index=train_end_index,\n",
    ")\n",
    "valid_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=valid_start_index,\n",
    "    end_index=valid_end_index,\n",
    ")\n",
    "test_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=test_start_index,\n",
    "    end_index=test_end_index,\n",
    ")\n",
    "\n",
    "tsp = TimeSeriesPreprocessor(\n",
    "    timestamp_column=timestamp_column,\n",
    "    id_columns=id_columns,\n",
    "    target_columns=forecast_columns,\n",
    "    scaling=True,\n",
    ")\n",
    "tsp.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(train_data),\n",
    "    id_columns=id_columns,\n",
    "    target_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "valid_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(valid_data),\n",
    "    id_columns=id_columns,\n",
    "    target_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "test_dataset = ForecastDFDataset(\n",
    "    tsp.preprocess(test_data),\n",
    "    id_columns=id_columns,\n",
    "    target_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction model\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading prediction model\")\n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    do_mask_input=False,\n",
    "    context_length=context_length,\n",
    "    patch_length=patch_length,\n",
    "    num_input_channels=len(forecast_columns),\n",
    "    patch_stride=8,\n",
    "    prediction_length=forecast_horizon,\n",
    "    d_model=64,\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=4,\n",
    "    ffn_dim=128,\n",
    "    dropout=0.05,\n",
    "    head_dropout=0.0,\n",
    "    pooling_type=None,\n",
    "    channel_attention=False,\n",
    "    scaling=\"std\",\n",
    "    loss=\"mse\",\n",
    "    pre_norm=True,\n",
    "    norm_type=\"batchnorm\",\n",
    "    positional_encoding_type = \"sincos\"\n",
    ")\n",
    "\n",
    "model = PatchTSTForPredictionOG(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTForPrediction(\n",
       "  (model): PatchTSTModel(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (masking): Identity()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTPredictionHead(\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (projection): Linear(in_features=4096, out_features=96, bias=True)\n",
       "    (dropout): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  531872\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=r\"checkpoints\\finetuned_og\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=30,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=1,  # num_workers,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=r\"checkpoints\\finetuned_og\\logs\",\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    ")\n",
    "\n",
    "# Create a new early stopping callback with faster convergence properties\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=15,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Doing forecasting training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1722ed5b5e454eb8cf3cd8ab2be1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4547, 'grad_norm': 0.7304683923721313, 'learning_rate': 9.666666666666667e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78b53a711854fb4b82965be469bdc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22187064588069916, 'eval_runtime': 5.4788, 'eval_samples_per_second': 508.322, 'eval_steps_per_second': 16.062, 'epoch': 1.0}\n",
      "{'loss': 0.4294, 'grad_norm': 56.91178512573242, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8275fdab4c454802a33f728296e95b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20501796901226044, 'eval_runtime': 5.4756, 'eval_samples_per_second': 508.62, 'eval_steps_per_second': 16.071, 'epoch': 2.0}\n",
      "{'loss': 0.3575, 'grad_norm': 0.34758299589157104, 'learning_rate': 9e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37df0b7257394698ae6d66d4ba246037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.215131014585495, 'eval_runtime': 5.5319, 'eval_samples_per_second': 503.448, 'eval_steps_per_second': 15.908, 'epoch': 3.0}\n",
      "{'loss': 0.3333, 'grad_norm': 1.2480909824371338, 'learning_rate': 8.666666666666667e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54882a9841b740bda4c587812eb5eac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21704818308353424, 'eval_runtime': 5.4449, 'eval_samples_per_second': 511.488, 'eval_steps_per_second': 16.162, 'epoch': 4.0}\n",
      "{'loss': 0.3143, 'grad_norm': 0.6654150485992432, 'learning_rate': 8.333333333333334e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a700fccc17f4c219d377f7075dfa657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21003295481204987, 'eval_runtime': 5.2603, 'eval_samples_per_second': 529.438, 'eval_steps_per_second': 16.729, 'epoch': 5.0}\n",
      "{'loss': 0.2964, 'grad_norm': 5.50455904006958, 'learning_rate': 8e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf306b7c690e4667a6b985ce8a37729c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21859948337078094, 'eval_runtime': 5.4901, 'eval_samples_per_second': 507.281, 'eval_steps_per_second': 16.029, 'epoch': 6.0}\n",
      "{'loss': 0.2787, 'grad_norm': 0.9314972162246704, 'learning_rate': 7.666666666666667e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fcd809a8ad4b16b5dbaab24d45676e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21238893270492554, 'eval_runtime': 5.3305, 'eval_samples_per_second': 522.465, 'eval_steps_per_second': 16.509, 'epoch': 7.0}\n",
      "{'loss': 0.2688, 'grad_norm': 0.9810602068901062, 'learning_rate': 7.333333333333333e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ae7bd14788410e865031ea839966ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22930219769477844, 'eval_runtime': 5.3769, 'eval_samples_per_second': 517.955, 'eval_steps_per_second': 16.366, 'epoch': 8.0}\n",
      "{'loss': 0.2609, 'grad_norm': 0.6435775756835938, 'learning_rate': 7e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec64a17ced3d484b95f06688bbb05b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22837860882282257, 'eval_runtime': 5.3224, 'eval_samples_per_second': 523.257, 'eval_steps_per_second': 16.534, 'epoch': 9.0}\n",
      "{'loss': 0.2533, 'grad_norm': 1.3154407739639282, 'learning_rate': 6.666666666666667e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f09681e83854670b0ab786b69640161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2197464555501938, 'eval_runtime': 5.2701, 'eval_samples_per_second': 528.451, 'eval_steps_per_second': 16.698, 'epoch': 10.0}\n",
      "{'loss': 0.2483, 'grad_norm': 2.067758798599243, 'learning_rate': 6.333333333333333e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0661d03e423a48b9a293518fb10bda91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22754190862178802, 'eval_runtime': 5.5293, 'eval_samples_per_second': 503.679, 'eval_steps_per_second': 15.915, 'epoch': 11.0}\n",
      "{'loss': 0.2451, 'grad_norm': 1.3195611238479614, 'learning_rate': 6e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4dfb6870fa4df3a8d5895e30f9a6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21759918332099915, 'eval_runtime': 5.6251, 'eval_samples_per_second': 495.107, 'eval_steps_per_second': 15.644, 'epoch': 12.0}\n",
      "{'loss': 0.2397, 'grad_norm': 2.0997567176818848, 'learning_rate': 5.666666666666667e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d403ebcd6ca344fe8dacd041dcad05be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2325953096151352, 'eval_runtime': 5.4756, 'eval_samples_per_second': 508.622, 'eval_steps_per_second': 16.071, 'epoch': 13.0}\n",
      "{'loss': 0.2365, 'grad_norm': 0.8184136152267456, 'learning_rate': 5.333333333333333e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b751ba322d421a8133ae96a2645364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24540932476520538, 'eval_runtime': 5.3396, 'eval_samples_per_second': 521.571, 'eval_steps_per_second': 16.481, 'epoch': 14.0}\n",
      "{'loss': 0.2319, 'grad_norm': 0.48072633147239685, 'learning_rate': 5e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b80e316396419da12e22716f35692d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26144689321517944, 'eval_runtime': 5.4743, 'eval_samples_per_second': 508.745, 'eval_steps_per_second': 16.075, 'epoch': 15.0}\n",
      "{'loss': 0.2287, 'grad_norm': 3.7258567810058594, 'learning_rate': 4.666666666666667e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217e284cad4241e685be694aa8d95b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23422588407993317, 'eval_runtime': 5.5892, 'eval_samples_per_second': 498.279, 'eval_steps_per_second': 15.745, 'epoch': 16.0}\n",
      "{'loss': 0.2261, 'grad_norm': 3.5560038089752197, 'learning_rate': 4.3333333333333334e-05, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1450a148f548a78d6f54c89d1864b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23462583124637604, 'eval_runtime': 5.2932, 'eval_samples_per_second': 526.148, 'eval_steps_per_second': 16.625, 'epoch': 17.0}\n",
      "{'train_runtime': 282.6786, 'train_samples_per_second': 852.523, 'train_steps_per_second': 26.744, 'train_loss': 0.2884405494070187, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4284, training_loss=0.2884405494070187, metrics={'train_runtime': 282.6786, 'train_samples_per_second': 852.523, 'train_steps_per_second': 26.744, 'total_flos': 1561899434016768.0, 'train_loss': 0.2884405494070187, 'epoch': 17.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\nDoing forecasting training\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0fc6fb7d434617977f63d04f2d2cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.286152720451355,\n",
       " 'eval_runtime': 5.5476,\n",
       " 'eval_samples_per_second': 502.015,\n",
       " 'eval_steps_per_second': 15.863,\n",
       " 'epoch': 17.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained encoder model\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchTSTModelJEPA(\n",
       "  (scaler): PatchTSTScaler(\n",
       "    (scaler): PatchTSTStdScaler()\n",
       "  )\n",
       "  (patchifier): PatchTSTPatchify()\n",
       "  (encoder): PatchTSTEncoder(\n",
       "    (embedder): PatchTSTEmbedding(\n",
       "      (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "    )\n",
       "    (positional_encoder): PatchTSTPositionalEncoding(\n",
       "      (positional_dropout): Identity()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x PatchTSTEncoderLayer(\n",
       "        (self_attn): PatchTSTAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (dropout_path1): Identity()\n",
       "        (norm_sublayer1): PatchTSTBatchNorm(\n",
       "          (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELUActivation()\n",
       "          (2): Identity()\n",
       "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (dropout_path3): Identity()\n",
       "        (norm_sublayer3): PatchTSTBatchNorm(\n",
       "          (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading pretrained encoder model\")\n",
    "encoder_model = PatchTSTModelJEPA.from_pretrained(r\"D:\\Coursework\\MTS\\timeseriesJEPA\\results\\PatchTST_Time300B_sl512_dm64_nh4_el3_fd64_bs256_lr0.0001\\checkpoint-14494\")\n",
    "print(\"Done\")\n",
    "encoder_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchTSTForPrediction(\n",
       "  (model): PatchTSTModelJEPA(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTPredictionHead(\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (projection): Linear(in_features=4096, out_features=96, bias=True)\n",
       "    (dropout): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading prediction model\")\n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    do_mask_input=False,\n",
    "    context_length=context_length,\n",
    "    patch_length=patch_length,\n",
    "    num_input_channels=len(forecast_columns),\n",
    "    patch_stride=patch_length,\n",
    "    prediction_length=forecast_horizon,\n",
    "    d_model=64,\n",
    "    num_attention_heads=4,\n",
    "    # num_hidden_layers=4,\n",
    "    ffn_dim=128,\n",
    "    dropout=0.05,\n",
    "    head_dropout=0.0,\n",
    "    pooling_type=None,\n",
    "    channel_attention=False,\n",
    "    scaling=\"std\",\n",
    "    loss=\"mse\",\n",
    "    pre_norm=True,\n",
    "    norm_type=\"batchnorm\",\n",
    "    positional_encoding_type = \"sincos\"\n",
    ")\n",
    "\n",
    "model = PatchTSTForPrediction(config=config, encoder_model=encoder_model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  393312\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  80448\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = sum([np.prod(p.size()) for p in encoder_model.parameters()])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=r\"checkpoints\\finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=30,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=1,  # num_workers,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=r\"checkpoints\\finetuned\\logs\",\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    ")\n",
    "\n",
    "# Create a new early stopping callback with faster convergence properties\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Doing forecasting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvg2523\u001b[0m (\u001b[33mhpml_4\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Coursework\\MTS\\timeseriesJEPA\\wandb\\run-20250126_225816-48ob770l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hpml_4/huggingface/runs/48ob770l' target=\"_blank\">checkpoints\\finetuned</a></strong> to <a href='https://wandb.ai/hpml_4/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hpml_4/huggingface' target=\"_blank\">https://wandb.ai/hpml_4/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hpml_4/huggingface/runs/48ob770l' target=\"_blank\">https://wandb.ai/hpml_4/huggingface/runs/48ob770l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2abe767231486e8159f41113abdf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5154, 'grad_norm': 2.2565743923187256, 'learning_rate': 9.666666666666667e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d93dd0d33d47d7a73ab825238f14db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2572374641895294, 'eval_runtime': 13.2845, 'eval_samples_per_second': 209.643, 'eval_steps_per_second': 6.624, 'epoch': 1.0}\n",
      "{'loss': 0.472, 'grad_norm': 28.936128616333008, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ed061e40f74521bb235c0a04e83f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2517375946044922, 'eval_runtime': 17.1383, 'eval_samples_per_second': 162.501, 'eval_steps_per_second': 5.135, 'epoch': 2.0}\n",
      "{'loss': 0.414, 'grad_norm': 0.8931271433830261, 'learning_rate': 9e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a161d47e454a460e9b17a062015f5937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23434366285800934, 'eval_runtime': 15.651, 'eval_samples_per_second': 177.944, 'eval_steps_per_second': 5.623, 'epoch': 3.0}\n",
      "{'loss': 0.4007, 'grad_norm': 1.4431954622268677, 'learning_rate': 8.666666666666667e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d6f9f686764f4295d51a8d8b074df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2360202521085739, 'eval_runtime': 16.589, 'eval_samples_per_second': 167.883, 'eval_steps_per_second': 5.305, 'epoch': 4.0}\n",
      "{'loss': 0.3909, 'grad_norm': 1.2231580018997192, 'learning_rate': 8.333333333333334e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5e7c5e11174dc5baa7396303f566c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2290770411491394, 'eval_runtime': 18.2698, 'eval_samples_per_second': 152.437, 'eval_steps_per_second': 4.817, 'epoch': 5.0}\n",
      "{'loss': 0.3824, 'grad_norm': 2.1518006324768066, 'learning_rate': 8e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606a50c9c24a4c72b3b8ca33dad6899f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22815313935279846, 'eval_runtime': 16.8901, 'eval_samples_per_second': 164.89, 'eval_steps_per_second': 5.21, 'epoch': 6.0}\n",
      "{'loss': 0.3765, 'grad_norm': 1.0791038274765015, 'learning_rate': 7.666666666666667e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b73498453a845b69e2b48f6959b37e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22582820057868958, 'eval_runtime': 14.5208, 'eval_samples_per_second': 191.793, 'eval_steps_per_second': 6.06, 'epoch': 7.0}\n",
      "{'loss': 0.3698, 'grad_norm': 0.7359057664871216, 'learning_rate': 7.333333333333333e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020d84715eae428693ef91eddb182b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2309047430753708, 'eval_runtime': 16.2536, 'eval_samples_per_second': 171.347, 'eval_steps_per_second': 5.414, 'epoch': 8.0}\n",
      "{'loss': 0.3674, 'grad_norm': 0.8775313496589661, 'learning_rate': 7e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d218d05376c2415b850d55100237e171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2255304455757141, 'eval_runtime': 16.8073, 'eval_samples_per_second': 165.701, 'eval_steps_per_second': 5.236, 'epoch': 9.0}\n",
      "{'loss': 0.363, 'grad_norm': 0.9937266111373901, 'learning_rate': 6.666666666666667e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2de9d849db24c7e86b9c613a5bc54da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22342795133590698, 'eval_runtime': 17.0761, 'eval_samples_per_second': 163.093, 'eval_steps_per_second': 5.153, 'epoch': 10.0}\n",
      "{'loss': 0.3599, 'grad_norm': 1.534043312072754, 'learning_rate': 6.333333333333333e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b4ab11bda34c639b6f2f83886d48c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22504965960979462, 'eval_runtime': 17.6074, 'eval_samples_per_second': 158.172, 'eval_steps_per_second': 4.998, 'epoch': 11.0}\n",
      "{'loss': 0.3572, 'grad_norm': 1.4988899230957031, 'learning_rate': 6e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2681be02e4d5455b8d6569b74727edf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22256019711494446, 'eval_runtime': 16.3304, 'eval_samples_per_second': 170.541, 'eval_steps_per_second': 5.389, 'epoch': 12.0}\n",
      "{'loss': 0.3539, 'grad_norm': 0.8637843132019043, 'learning_rate': 5.666666666666667e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0da7438c6c4bdaa1475fb03ae6be8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22500784695148468, 'eval_runtime': 16.5025, 'eval_samples_per_second': 168.762, 'eval_steps_per_second': 5.333, 'epoch': 13.0}\n",
      "{'loss': 0.3522, 'grad_norm': 1.1694121360778809, 'learning_rate': 5.333333333333333e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fcb825e4a94595883b580ab5cf58a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22453242540359497, 'eval_runtime': 16.3247, 'eval_samples_per_second': 170.6, 'eval_steps_per_second': 5.391, 'epoch': 14.0}\n",
      "{'loss': 0.35, 'grad_norm': 0.783818244934082, 'learning_rate': 5e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e24886d2ec3417891b4556f2c30c779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23019136488437653, 'eval_runtime': 14.0891, 'eval_samples_per_second': 197.67, 'eval_steps_per_second': 6.246, 'epoch': 15.0}\n",
      "{'train_runtime': 676.3519, 'train_samples_per_second': 356.309, 'train_steps_per_second': 11.178, 'train_loss': 0.38834564975960545, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3780, training_loss=0.38834564975960545, metrics={'train_runtime': 676.3519, 'train_samples_per_second': 356.309, 'train_steps_per_second': 11.178, 'total_flos': 1227571133644800.0, 'train_loss': 0.38834564975960545, 'epoch': 15.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\nDoing forecasting training\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d740abc3d3549bca4794d360248f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29088908433914185,\n",
       " 'eval_runtime': 13.4968,\n",
       " 'eval_samples_per_second': 206.346,\n",
       " 'eval_steps_per_second': 6.52,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
