{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import PatchTSTConfig, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import PatchTSTForPrediction as PatchTSTForPredictionOG\n",
    "from TimeSeriesJEPA.models import PatchTSTModelJEPA, PatchTSTForPrediction\n",
    "from TimeSeriesJEPA.datasets.benchmark_dataset import BenchmarkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"D:\\Coursework\\MTS\\dataset\\ETT-small\\ETTh1.csv\"\n",
    "dataset = \"ETTh2\"\n",
    "num_workers = 4  # Reduce this if you have low number of CPU cores\n",
    "batch_size = 32  # Reduce if not enough GPU memory available\n",
    "context_length = 512\n",
    "forecast_horizon = 96\n",
    "patch_length = 8\n",
    "num_input_channels=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:  (17420, 7)\n",
      "Total data size:  (17420, 7)\n",
      "dataset loaded, total size:  8033 2785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainwindowds = BenchmarkDataset(csv_path=csv_path, context_length=context_length, prediction_length=forecast_horizon, flag='train', returndict=True)\n",
    "valwindowds = BenchmarkDataset(csv_path=csv_path, context_length=context_length, prediction_length=forecast_horizon, flag='test', returndict=True)\n",
    "print(\"dataset loaded, total size: \", len(trainwindowds), len(valwindowds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction model\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading prediction model\")\n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    do_mask_input=False,\n",
    "    context_length=context_length,\n",
    "    patch_length=patch_length,\n",
    "    num_input_channels=num_input_channels,\n",
    "    patch_stride=8,\n",
    "    prediction_length=forecast_horizon,\n",
    "    d_model=64,\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=4,\n",
    "    ffn_dim=128,\n",
    "    dropout=0.05,\n",
    "    head_dropout=0.2,\n",
    "    pooling_type=None,\n",
    "    channel_attention=False,\n",
    "    scaling=\"std\",\n",
    "    loss=\"mse\",\n",
    "    pre_norm=True,\n",
    "    norm_type=\"batchnorm\",\n",
    "    positional_encoding_type = \"sincos\"\n",
    ")\n",
    "\n",
    "model = PatchTSTForPredictionOG(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTForPrediction(\n",
       "  (model): PatchTSTModel(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (masking): Identity()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTPredictionHead(\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (projection): Linear(in_features=4096, out_features=96, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  531872\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=r\"checkpoints\\finetuned_og\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=30,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=1,  # num_workers,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=r\"checkpoints\\finetuned_og\\logs\",\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    ")\n",
    "\n",
    "# Create a new early stopping callback with faster convergence properties\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=15,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=trainwindowds,\n",
    "    eval_dataset=valwindowds,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Doing forecasting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvg2523\u001b[0m (\u001b[33mhpml_4\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Coursework\\MTS\\timeseriesJEPA\\wandb\\run-20250130_002843-21akp7ot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hpml_4/huggingface/runs/21akp7ot' target=\"_blank\">checkpoints\\finetuned_og</a></strong> to <a href='https://wandb.ai/hpml_4/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hpml_4/huggingface' target=\"_blank\">https://wandb.ai/hpml_4/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hpml_4/huggingface/runs/21akp7ot' target=\"_blank\">https://wandb.ai/hpml_4/huggingface/runs/21akp7ot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f670c1e4b8244f2bd5c06505b8c059e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4042, 'grad_norm': 0.9541079998016357, 'learning_rate': 9.666666666666667e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2ad5a7e4714198a6c9659c4a8ecd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3811493515968323, 'eval_runtime': 5.2567, 'eval_samples_per_second': 529.802, 'eval_steps_per_second': 16.741, 'epoch': 1.0}\n",
      "{'loss': 0.3514, 'grad_norm': 1.9452170133590698, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352bbea2cac246a6889d2d28d6192ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37523433566093445, 'eval_runtime': 5.2197, 'eval_samples_per_second': 533.557, 'eval_steps_per_second': 16.859, 'epoch': 2.0}\n",
      "{'loss': 0.3389, 'grad_norm': 0.8461436033248901, 'learning_rate': 9e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d1044e0aaa40819e4dc1f343670d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3707025945186615, 'eval_runtime': 5.2806, 'eval_samples_per_second': 527.404, 'eval_steps_per_second': 16.665, 'epoch': 3.0}\n",
      "{'loss': 0.3272, 'grad_norm': 2.879274368286133, 'learning_rate': 8.666666666666667e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d562be00714389a96a7a65b3a807ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37453651428222656, 'eval_runtime': 5.2984, 'eval_samples_per_second': 525.632, 'eval_steps_per_second': 16.609, 'epoch': 4.0}\n",
      "{'loss': 0.3185, 'grad_norm': 2.0323400497436523, 'learning_rate': 8.333333333333334e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4709d75782024693b7a6f8b736126932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3721573054790497, 'eval_runtime': 5.6978, 'eval_samples_per_second': 488.787, 'eval_steps_per_second': 15.445, 'epoch': 5.0}\n",
      "{'loss': 0.3147, 'grad_norm': 3.750199317932129, 'learning_rate': 8e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33563aef1da241f387053c778ec2aa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37636634707450867, 'eval_runtime': 5.7483, 'eval_samples_per_second': 484.493, 'eval_steps_per_second': 15.309, 'epoch': 6.0}\n",
      "{'loss': 0.3075, 'grad_norm': 4.1687822341918945, 'learning_rate': 7.666666666666667e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fe59d894004aa988495e7b911ed76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.394731342792511, 'eval_runtime': 5.7135, 'eval_samples_per_second': 487.44, 'eval_steps_per_second': 15.402, 'epoch': 7.0}\n",
      "{'loss': 0.3026, 'grad_norm': 2.041572093963623, 'learning_rate': 7.333333333333333e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc7fa6b59ec41f5bd9e4fee02d7ab79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4063495993614197, 'eval_runtime': 5.5947, 'eval_samples_per_second': 497.795, 'eval_steps_per_second': 15.729, 'epoch': 8.0}\n",
      "{'loss': 0.2998, 'grad_norm': 15.285344123840332, 'learning_rate': 7e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2ae36848914ef8af1b4fde01c7b013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4476419985294342, 'eval_runtime': 6.0108, 'eval_samples_per_second': 463.335, 'eval_steps_per_second': 14.64, 'epoch': 9.0}\n",
      "{'loss': 0.2945, 'grad_norm': 3.6338367462158203, 'learning_rate': 6.666666666666667e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa5dfcc0ce4419b9b5e3aafe13a06dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5132741928100586, 'eval_runtime': 6.3373, 'eval_samples_per_second': 439.461, 'eval_steps_per_second': 13.886, 'epoch': 10.0}\n",
      "{'loss': 0.2913, 'grad_norm': 5.302101135253906, 'learning_rate': 6.333333333333333e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538a7f0adbbe4f1fba0aa37d084f7d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5773695111274719, 'eval_runtime': 7.9016, 'eval_samples_per_second': 352.461, 'eval_steps_per_second': 11.137, 'epoch': 11.0}\n",
      "{'loss': 0.2882, 'grad_norm': 2.5573930740356445, 'learning_rate': 6e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c455b609724a29905754e71d22dd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5311248302459717, 'eval_runtime': 7.4881, 'eval_samples_per_second': 371.922, 'eval_steps_per_second': 11.752, 'epoch': 12.0}\n",
      "{'loss': 0.2838, 'grad_norm': 2.961695671081543, 'learning_rate': 5.666666666666667e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33e436710ee4d799167079f81680d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5937477946281433, 'eval_runtime': 5.7443, 'eval_samples_per_second': 484.826, 'eval_steps_per_second': 15.319, 'epoch': 13.0}\n",
      "{'loss': 0.2815, 'grad_norm': 2.146162271499634, 'learning_rate': 5.333333333333333e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1d7204a95c48a9b87be6cafc3ce35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6364628076553345, 'eval_runtime': 6.3125, 'eval_samples_per_second': 441.186, 'eval_steps_per_second': 13.941, 'epoch': 14.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDoing forecasting training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[1;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[0;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[1;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[0;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[0;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(epoch_iterator)]\n\u001b[0;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\accelerate\\data_loader.py:549\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_epoch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration)\n\u001b[1;32m--> 549\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nDoing forecasting training\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563bad1da6a74283b795b17004163352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6364628076553345, 'eval_runtime': 5.5428, 'eval_samples_per_second': 502.458, 'eval_steps_per_second': 15.877, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6364628076553345,\n",
       " 'eval_runtime': 5.5428,\n",
       " 'eval_samples_per_second': 502.458,\n",
       " 'eval_steps_per_second': 15.877,\n",
       " 'epoch': 14.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(valwindowds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained encoder model\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchTSTModelJEPA(\n",
       "  (scaler): PatchTSTScaler(\n",
       "    (scaler): PatchTSTStdScaler()\n",
       "  )\n",
       "  (patchifier): PatchTSTPatchify()\n",
       "  (encoder): PatchTSTEncoder(\n",
       "    (embedder): PatchTSTEmbedding(\n",
       "      (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "    )\n",
       "    (positional_encoder): PatchTSTPositionalEncoding(\n",
       "      (positional_dropout): Identity()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x PatchTSTEncoderLayer(\n",
       "        (self_attn): PatchTSTAttention(\n",
       "          (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (dropout_path1): Identity()\n",
       "        (norm_sublayer1): PatchTSTBatchNorm(\n",
       "          (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELUActivation()\n",
       "          (2): Identity()\n",
       "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (dropout_path3): Identity()\n",
       "        (norm_sublayer3): PatchTSTBatchNorm(\n",
       "          (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading pretrained encoder model\")\n",
    "encoder_model = PatchTSTModelJEPA.from_pretrained(r\"D:\\Coursework\\MTS\\timeseriesJEPA\\results\\PatchTST_etth1_sl512_enc_dm64_nh16_el3_fd64_pred_dm32_nh2_el1_fd32_bs256_lr0.0001_pe10_clean_data\\checkpoint-320\")\n",
    "print(\"Done\")\n",
    "encoder_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prediction model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchTSTForPrediction(\n",
       "  (model): PatchTSTModelJEPA(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=8, out_features=64, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTPredictionHead(\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (projection): Linear(in_features=4096, out_features=96, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading prediction model\")\n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    do_mask_input=False,\n",
    "    context_length=context_length,\n",
    "    patch_length=patch_length,\n",
    "    num_input_channels=num_input_channels,\n",
    "    patch_stride=patch_length,\n",
    "    prediction_length=forecast_horizon,\n",
    "    d_model=64,\n",
    "    num_attention_heads=4,\n",
    "    # num_hidden_layers=4,\n",
    "    ffn_dim=128,\n",
    "    dropout=0.05,\n",
    "    head_dropout=0.2,\n",
    "    pooling_type=None,\n",
    "    channel_attention=False,\n",
    "    scaling=\"std\",\n",
    "    loss=\"mse\",\n",
    "    pre_norm=True,\n",
    "    norm_type=\"batchnorm\",\n",
    "    positional_encoding_type = \"sincos\"\n",
    ")\n",
    "\n",
    "model = PatchTSTForPrediction(config=config, encoder_model=encoder_model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  393312\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters:  80448\n"
     ]
    }
   ],
   "source": [
    "params = sum([np.prod(p.size()) for p in encoder_model.parameters()])\n",
    "print(\"encoder parameters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omen\\anaconda3\\envs\\mts\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=r\"checkpoints\\finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.001,\n",
    "    num_train_epochs=30,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=1,  # num_workers,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=r\"checkpoints\\finetuned\\logs\",\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    ")\n",
    "\n",
    "# Create a new early stopping callback with faster convergence properties\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=trainwindowds,\n",
    "    eval_dataset=valwindowds,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Doing forecasting training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde353c0abe453aaa20e1a1a264dcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6613, 'grad_norm': 4.980772972106934, 'learning_rate': 0.0009666666666666667, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d20dbdbf7a49aea692263cd21117b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5397689938545227, 'eval_runtime': 7.4838, 'eval_samples_per_second': 372.139, 'eval_steps_per_second': 11.759, 'epoch': 1.0}\n",
      "{'loss': 0.4985, 'grad_norm': 4.903587818145752, 'learning_rate': 0.0009333333333333333, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdbf08ba9f044fa9b21b5fe6078e0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47783002257347107, 'eval_runtime': 6.6671, 'eval_samples_per_second': 417.721, 'eval_steps_per_second': 13.199, 'epoch': 2.0}\n",
      "{'loss': 0.4527, 'grad_norm': 2.5112364292144775, 'learning_rate': 0.0009000000000000001, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d39a43d3aa4ca5b6aeacf701844b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4736664891242981, 'eval_runtime': 7.2528, 'eval_samples_per_second': 383.989, 'eval_steps_per_second': 12.133, 'epoch': 3.0}\n",
      "{'loss': 0.426, 'grad_norm': 3.6455376148223877, 'learning_rate': 0.0008666666666666667, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63efb615f1743b4b8c90a8e05202116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5290011167526245, 'eval_runtime': 6.5681, 'eval_samples_per_second': 424.021, 'eval_steps_per_second': 13.398, 'epoch': 4.0}\n",
      "{'loss': 0.4091, 'grad_norm': 3.5920705795288086, 'learning_rate': 0.0008333333333333334, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f8b5316696478dabe2a95b5ed146b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45151111483573914, 'eval_runtime': 6.5127, 'eval_samples_per_second': 427.623, 'eval_steps_per_second': 13.512, 'epoch': 5.0}\n",
      "{'loss': 0.3995, 'grad_norm': 3.834648847579956, 'learning_rate': 0.0008, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bf5dab4c2b403da945aaceb0a2f29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4501143991947174, 'eval_runtime': 6.914, 'eval_samples_per_second': 402.803, 'eval_steps_per_second': 12.728, 'epoch': 6.0}\n",
      "{'loss': 0.3918, 'grad_norm': 3.566815137863159, 'learning_rate': 0.0007666666666666667, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6304d19355ed45239b1e1f075bc53a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4298003315925598, 'eval_runtime': 6.5418, 'eval_samples_per_second': 425.726, 'eval_steps_per_second': 13.452, 'epoch': 7.0}\n",
      "{'loss': 0.3881, 'grad_norm': 2.9866280555725098, 'learning_rate': 0.0007333333333333333, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c05b90e03410f9ff85ee8f8c52678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5304861664772034, 'eval_runtime': 7.1545, 'eval_samples_per_second': 389.263, 'eval_steps_per_second': 12.3, 'epoch': 8.0}\n",
      "{'loss': 0.3868, 'grad_norm': 7.437785625457764, 'learning_rate': 0.0007, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc801c1008a645c1a510570f76977ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43573859333992004, 'eval_runtime': 6.4926, 'eval_samples_per_second': 428.947, 'eval_steps_per_second': 13.554, 'epoch': 9.0}\n",
      "{'loss': 0.3816, 'grad_norm': 3.3538718223571777, 'learning_rate': 0.0006666666666666666, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280c1027b1fc45a49e2418ea2dad529d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45737752318382263, 'eval_runtime': 7.0766, 'eval_samples_per_second': 393.55, 'eval_steps_per_second': 12.435, 'epoch': 10.0}\n",
      "{'loss': 0.3793, 'grad_norm': 5.836106300354004, 'learning_rate': 0.0006333333333333333, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f442d09201e04210beb48dbbe9304ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4153909385204315, 'eval_runtime': 6.6538, 'eval_samples_per_second': 418.558, 'eval_steps_per_second': 13.226, 'epoch': 11.0}\n",
      "{'loss': 0.3754, 'grad_norm': 3.6648576259613037, 'learning_rate': 0.0006, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ed89f57e0749c79f2f5a0ede27039d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44915273785591125, 'eval_runtime': 6.6798, 'eval_samples_per_second': 416.929, 'eval_steps_per_second': 13.174, 'epoch': 12.0}\n",
      "{'loss': 0.3748, 'grad_norm': 2.477010488510132, 'learning_rate': 0.0005666666666666667, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4efb57147745c6932c37b5c0cc03a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4374348521232605, 'eval_runtime': 6.6765, 'eval_samples_per_second': 417.132, 'eval_steps_per_second': 13.18, 'epoch': 13.0}\n",
      "{'loss': 0.3731, 'grad_norm': 3.40985369682312, 'learning_rate': 0.0005333333333333334, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6754891a6d41798a5946024d49fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.403964102268219, 'eval_runtime': 7.4981, 'eval_samples_per_second': 371.426, 'eval_steps_per_second': 11.736, 'epoch': 14.0}\n",
      "{'loss': 0.3682, 'grad_norm': 2.3559036254882812, 'learning_rate': 0.0005, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a31d66679fd400f95746c9e1312de66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48144346475601196, 'eval_runtime': 7.2189, 'eval_samples_per_second': 385.793, 'eval_steps_per_second': 12.19, 'epoch': 15.0}\n",
      "{'loss': 0.3718, 'grad_norm': 3.8589298725128174, 'learning_rate': 0.00046666666666666666, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aa44db83b045fe8d55c63fbfa755bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4074825346469879, 'eval_runtime': 7.0001, 'eval_samples_per_second': 397.853, 'eval_steps_per_second': 12.571, 'epoch': 16.0}\n",
      "{'loss': 0.3647, 'grad_norm': 3.4911935329437256, 'learning_rate': 0.00043333333333333337, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab083e1776458c8581012e1411565c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4393209218978882, 'eval_runtime': 7.3047, 'eval_samples_per_second': 381.262, 'eval_steps_per_second': 12.047, 'epoch': 17.0}\n",
      "{'loss': 0.3639, 'grad_norm': 3.569049119949341, 'learning_rate': 0.0004, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdc1d031bba4345b702f86ce09f5889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43277400732040405, 'eval_runtime': 7.4686, 'eval_samples_per_second': 372.894, 'eval_steps_per_second': 11.783, 'epoch': 18.0}\n",
      "{'loss': 0.3645, 'grad_norm': 2.9429492950439453, 'learning_rate': 0.00036666666666666667, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6b991c25994a70a9086968dc8e0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4011828899383545, 'eval_runtime': 7.491, 'eval_samples_per_second': 371.781, 'eval_steps_per_second': 11.747, 'epoch': 19.0}\n",
      "{'loss': 0.3595, 'grad_norm': 3.4245247840881348, 'learning_rate': 0.0003333333333333333, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db8860e1b37460d872489fa62276996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4032125174999237, 'eval_runtime': 7.2496, 'eval_samples_per_second': 384.157, 'eval_steps_per_second': 12.139, 'epoch': 20.0}\n",
      "{'loss': 0.3594, 'grad_norm': 3.7439441680908203, 'learning_rate': 0.0003, 'epoch': 21.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d7804a12044a258027f3a32c46bed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3917330503463745, 'eval_runtime': 7.1304, 'eval_samples_per_second': 390.583, 'eval_steps_per_second': 12.342, 'epoch': 21.0}\n",
      "{'loss': 0.358, 'grad_norm': 2.484614133834839, 'learning_rate': 0.0002666666666666667, 'epoch': 22.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e5c2141cfa4c27ad1932ec6842ed81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3810132145881653, 'eval_runtime': 6.9569, 'eval_samples_per_second': 400.324, 'eval_steps_per_second': 12.649, 'epoch': 22.0}\n",
      "{'loss': 0.3559, 'grad_norm': 2.5834968090057373, 'learning_rate': 0.00023333333333333333, 'epoch': 23.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6adb422ffc4bd09deec9cd4004f65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3937840163707733, 'eval_runtime': 6.4924, 'eval_samples_per_second': 428.966, 'eval_steps_per_second': 13.554, 'epoch': 23.0}\n",
      "{'loss': 0.3534, 'grad_norm': 2.6448538303375244, 'learning_rate': 0.0002, 'epoch': 24.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f194fd9a6efe467d95b4f4d5cb054d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.381401002407074, 'eval_runtime': 6.1101, 'eval_samples_per_second': 455.799, 'eval_steps_per_second': 14.402, 'epoch': 24.0}\n",
      "{'loss': 0.3508, 'grad_norm': 2.158303737640381, 'learning_rate': 0.00016666666666666666, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a086a5148bf54718b136f6edcd55e9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3745259940624237, 'eval_runtime': 5.9995, 'eval_samples_per_second': 464.207, 'eval_steps_per_second': 14.668, 'epoch': 25.0}\n",
      "{'loss': 0.3504, 'grad_norm': 2.6632256507873535, 'learning_rate': 0.00013333333333333334, 'epoch': 26.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a16f27d963440cabeafb8a82d87fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3933075964450836, 'eval_runtime': 6.297, 'eval_samples_per_second': 442.274, 'eval_steps_per_second': 13.975, 'epoch': 26.0}\n",
      "{'loss': 0.3481, 'grad_norm': 5.120226860046387, 'learning_rate': 0.0001, 'epoch': 27.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e56d029ca9d4f14a1e47d1c25e4d479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37319839000701904, 'eval_runtime': 6.707, 'eval_samples_per_second': 415.24, 'eval_steps_per_second': 13.121, 'epoch': 27.0}\n",
      "{'loss': 0.347, 'grad_norm': 3.8680896759033203, 'learning_rate': 6.666666666666667e-05, 'epoch': 28.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d10a39fe554f56b89fe2c82f637b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3664674460887909, 'eval_runtime': 5.9853, 'eval_samples_per_second': 465.307, 'eval_steps_per_second': 14.703, 'epoch': 28.0}\n",
      "{'loss': 0.3437, 'grad_norm': 3.653182029724121, 'learning_rate': 3.3333333333333335e-05, 'epoch': 29.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061419e1495b42238ef9defce01e5b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36917296051979065, 'eval_runtime': 6.6945, 'eval_samples_per_second': 416.015, 'eval_steps_per_second': 13.145, 'epoch': 29.0}\n",
      "{'loss': 0.3431, 'grad_norm': 5.6609954833984375, 'learning_rate': 0.0, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbd5777db3b48a283db013c7480ae37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3624768555164337, 'eval_runtime': 6.617, 'eval_samples_per_second': 420.883, 'eval_steps_per_second': 13.299, 'epoch': 30.0}\n",
      "{'train_runtime': 498.9284, 'train_samples_per_second': 483.015, 'train_steps_per_second': 15.152, 'train_loss': 0.3866818846848907, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7560, training_loss=0.3866818846848907, metrics={'train_runtime': 498.9284, 'train_samples_per_second': 483.015, 'train_steps_per_second': 15.152, 'total_flos': 2455142267289600.0, 'train_loss': 0.3866818846848907, 'epoch': 30.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\nDoing forecasting training\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1946278428584d1b88b90d0d8e0a093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3624768555164337,\n",
       " 'eval_runtime': 5.8795,\n",
       " 'eval_samples_per_second': 473.679,\n",
       " 'eval_steps_per_second': 14.967,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(valwindowds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
